# What Is ChatGPT Doing … and Why Does It Work?

Stephen Wolfram, February 14, 2023

## It’s Just Adding One Word at a Time

ChatGPT 可以自动生成读起来甚至表面上像人类书写的文本，这一点非常了不起，也出乎意料。但它是如何做到的呢？它为什么能做到？我在这里的目的是粗略地介绍一下 ChatGPT 内部的情况，然后探讨它为什么能如此出色地生成我们认为有意义的文本。首先，我想说的是，我将专注于事情的全貌--虽然我会提到一些工程细节，但我不会深入探讨。（我所说内容的精髓同样适用于当前的其他 "大型语言模型"[LLMs]，也适用于 ChatGPT）。

首先要解释的是，ChatGPT 从根本上说一直在努力做的事情就是对目前所获得的文本进行 "合理的延续"，这里的 "合理 "指的是 "在看到人们在数十亿个网页上所写的内容等之后，人们可能期望某人写出的内容"。

比方说，我们有这样一段文字："The best thing about AI is its ability to"。想象一下，扫描数十亿页人类书写的文本（比如网络上和数字化书籍中的文本），然后找到这些文本的所有实例--然后再看看下一个词出现的频率是多少。ChatGPT 就能有效地做到这一点，只不过（正如我将解释的那样）它并不看文字的字面意思，而是寻找在某种意义上 "意义匹配 "的东西。但最终结果是，它会生成一个可能排在后面的词的排序列表以及 "概率"：

![Alt text](https://content.wolfram.com/sites/43/2023/02/sw021423img1.png)

最了不起的是，当 ChatGPT 做一些类似于写作文的事情时，它所做的本质上只是一遍又一遍地询问 "鉴于目前的文本，下一个词应该是什么？"--每次都添加一个词。（更准确地说，正如我将要解释的那样，它是在添加一个 "token"，这可能只是一个词的一部分，这就是为什么它有时会 "创造新词"）。

但是，好吧，在每个步骤中，它都会得到一个带概率的单词表。但它究竟应该选择哪个词添加到它正在写的文章（或其他东西）中呢？人们可能会认为应该是 "排名最高 "的词（即 "概率 "最高的词）。但就在这时，一些巫术开始悄然出现。因为出于某种原因--也许有一天我们会对这种原因有科学式的理解--如果我们总是选择排名最高的单词，我们通常会得到一篇非常 "平淡 "的作文，似乎从未 "表现出任何创造性"（甚至有时会逐字重复）。但如果有时（随意）选取排名较低的词，我们就会得到一篇 "更有趣 "的文章。

这里的随机性意味着，如果我们多次使用同一个提示，每次都可能得到不同的作文。而且，为了与巫术的理念保持一致，还有一个所谓的 "temperature" 参数，它决定了排名较低的词被使用的频率，而对于作文生成来说，0.8 的 "temperature" 似乎是最好的。（值得强调的是，这里并没有使用任何 "理论"；这只是一个在实践中行之有效的问题。举例来说，"温度 "的概念之所以存在，是因为恰好使用了统计物理学中熟悉的指数分布，但这与 "物理 "并无关联--至少就我们所知是这样）。

在我们继续之前，我应该解释一下，为了便于说明，我通常不会使用 ChatGPT 中的完整系统；相反，我通常会使用更简单的 GPT-2 系统，它有一个很好的特点，就是足够小，可以在标准的台式电脑上运行。因此，在我展示的所有内容中，我都会包含明确的 Wolfram 语言代码，您可以在自己的电脑上立即运行。(点击这里的任何图片，即可复制其背后的代码）。

例如，下面是获取上述概率表的方法。首先，我们必须检索底层的 "语言模型 "神经网络：

![Alt text](https://content.wolfram.com/sites/43/2023/02/sw021423img2.png)

稍后，我们将进入这个神经网络，了解它是如何工作的。但现在，我们只需将这个 "网络模型 "作为一个黑盒子，应用到我们目前的文本中，然后根据概率找出该模型认为应该遵循的前 5 个单词：

![Alt text](https://content.wolfram.com/sites/43/2023/02/sw021423img3.png)

这样就可以将结果转换成格式化的 "数据集"：

![Alt text](https://content.wolfram.com/sites/43/2023/02/sw021423img4.png)

下面是重复 "应用模型 "的结果--每一步都添加概率最高的单词（在此代码中指定为模型中的 "decision"）：

![Alt text](https://content.wolfram.com/sites/43/2023/02/sw021423img5.png)

如果时间再长一点会怎样？在这种（"zero temperature"）情况下，很快就会出现混乱和重复：

![Alt text](https://content.wolfram.com/sites/43/2023/02/sw021423img6.png)

但是，如果不总是选择 "顶级 "词，而是有时随机选择 "非顶级 "词（"随机性 "相当于 "temperature "0.8），又会怎样呢？同样可以建立文本：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img7.png)

而每次这样做，都会做出不同的随机选择，文本也会不同，就像这 5 个例子一样：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img8.png)

值得注意的是，即使在第一步，也有很多可能的 "下一个词 "可供选择（温度为 0.8），尽管它们的概率下降得很快（是的，对数图上的直线对应于 $n^{-1}$ 的 "幂律 "衰减，这是语言统计的一般特征）：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img10.png)

那么，如果时间更长会发生什么呢？下面是一个随机例子。这个例子比最前面那个词（zero temperature）的情况要好一些，但还是有点奇怪：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img11A.png)

这是用最简单的 GPT-2 型号（2019 年）完成的。使用更新、更大的 GPT-3 型号，效果会更好。下面是使用同样的 "提示"，但使用最大的 GPT-3 型号时产生的顶部字词（zero temperature）文本：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img12.png)

下面是一个 "温度 0.8 "的随机例子：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img13.png)

## Where Do the Probabilities Come From?

好了，ChatGPT 总是根据概率来选择下一个单词。但这些概率从何而来呢？让我们从一个更简单的问题开始。让我们考虑一次生成一个字母（而不是单词）的英文文本。我们如何计算出每个字母的概率呢？

我们可以做的最简单的事情就是抽取英文文本样本，计算不同字母在其中出现的频率。例如，计算维基百科中关于 "猫 "的文章中出现的字母：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img14-edit.png)

这对 "狗 "来说也是一样：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img15.png)

结果相似，但不尽相同（"o "无疑在 "dogs "冠词中更常见，因为毕竟它出现在 "dog "一词本身中）。尽管如此，如果我们抽取的英语文本样本足够多，我们还是可以期待最终得到至少相当一致的结果：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img16.png)

下面是我们用这些概率生成字母序列的示例：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img17.png)

我们可以通过添加空格将其分解为 "单词"，就像添加具有一定概率的字母一样：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img18.png)

我们可以通过迫使 "单词长度 "的分布与英语中的分布相一致，在制造 "单词 "方面做得更好一些：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img19.png)

我们在这里并没有得到任何 "actual words"，但结果看起来略有好转。不过，要想更进一步，我们需要做的不仅仅是随机挑选每个字母。举例来说，我们知道，如果有一个 "q"，那么下一个字母基本上就是 "u"。

下面是字母单独出现的概率图：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img20.png)

下面的图表显示了典型英语文本中成对字母（"2-grams"）的概率。可能出现的第一个字母显示在页面的横向，第二个字母显示在页面的纵向：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img21.png)

例如，我们可以看到，除了 "u "行之外，"q "列是空白的（概率为零）。好了，现在我们不再一次生成一个字母的 "单词"，而是使用这些 "2-gram "概率，一次生成两个字母的 "单词"。下面是一个结果样本--其中恰好包含了一些 "实际单词"：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img22.png)

有了足够多的英文文本，我们不仅可以对单个字母或字母对（2-grams）的概率，还可以对较长的字母组合的概率做出相当准确的估计。如果我们生成的 "随机单词 "的 n-gram 概率逐渐变长，我们就会发现它们逐渐变得 "more realistic"：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img23.png)

但是，让我们现在假设--或多或少像 ChatGPT 所做的那样--我们处理的是整个单词，而不是字母。英语中大约有 4 万个比较常用的单词。通过查看大量的英语文本语料库（比如几百万本书，共几千亿个单词），我们可以估算出每个单词的常用程度。利用这一点，我们就可以开始生成 "句子"，其中的每个单词都是独立随机抽取的，与出现在语料库中的概率相同。下面是我们得到的一个样本：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img24.png)

毫不奇怪，这是无稽之谈。那么，我们怎样才能做得更好呢？就像处理字母一样，我们不仅可以开始考虑单词的概率，还可以考虑词对或更长的 n-gram 的概率。下面是我们从 "cat"（猫）这一单词开始得到的 5 个例子：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img25.png)

它看起来越来越 "合理 "了。我们可以想象，如果我们能够使用足够长的 n-gram，我们基本上就能 "得到一个 ChatGPT"--也就是说，我们会得到一个东西，它能生成具有 "正确的整体作文概率 "的作文长单词序列。但问题是：我们根本没有足够多的英语文章来推导出这些概率。

在对网络的抓取中，可能有几千亿个单词；在已经数字化的书籍中，可能又有几千亿个单词。但是，即使是 40,000 个常用词，可能出现的 2-grams 的数量也已经达到了 16 亿，而可能出现的 3-grams 的数量更是高达 60 万亿。因此，我们根本无法从现有的文本中估算出所有这些词的概率。而到了 20 个单词的 "文章片段 "时，可能性的数量已经超过了宇宙中粒子的数量，所以从某种意义上说，我们永远不可能把它们全部写下来。

那么我们能做些什么呢？最重要的想法是建立一个模型，让我们能够估算出序列出现的概率--即使我们从未在所查看的文本语料库中明确看到过这些序列。而 ChatGPT 的核心正是一个所谓的 "大型语言模型"（LLM），它的建立可以很好地估计这些概率。

## What Is a Model?

假设你想知道（就像伽利略在 15 世纪晚期所做的）从比萨斜塔的每一层投下一颗炮弹到落地需要多长时间。那么，你可以测量每种情况下的时间，并将结果列成表格。或者，你也可以采用理论科学的精髓：建立一个模型，给出计算答案的某种程序，而不仅仅是测量和记住每种情况。

假设我们有炮弹从不同楼层落下所需的时间数据（有点理想化）：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img26.png)

我们如何计算出从我们没有明确数据的地板上掉下来需要多长时间？在这种特殊情况下，我们可以利用已知的物理定律来计算。但是，如果我们只有数据，而不知道有什么基本定律支配着它。那么，我们可以做一个数学上的猜测，比如，也许我们应该用一条直线作为模型：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img27.png)

我们可以选择不同的直线。但这是平均而言最接近所给数据的一条直线。根据这条直线，我们可以估算出任何楼层的下降时间。

我们怎么会知道在这里使用直线呢？在某种程度上，我们并不知道。这只是数学上很简单的东西，而我们已经习惯了这样一个事实，即我们测量的很多数据都被数学上简单的东西很好地拟合了。我们可以尝试一些数学上更复杂的方法--比如说 $a + bx + cx^2$ --然后在这种情况下，我们会做得更好：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img29.png)

不过也有可能出错。比如，我们用 $a + b/x + c\sin(x)$ 的话最好只能做成这样：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img33.png)

值得理解的是，从来没有 "model-less model"。你所使用的任何模型都有一些特定的底层结构，然后有一组 "你可以转动的旋钮"（即你可以设置的参数）来适应你的数据。在 ChatGPT 中，使用了大量这样的 "旋钮"--实际上有 1750 亿个。

但难能可贵的是，ChatGPT 的底层结构--"仅仅 "有这么多参数--就足以建立一个模型，"足够好地 "计算下一个词的概率，从而为我们提供合理的长篇文章。

## Models for Human-Like Tasks

我们上面举的例子涉及为数字数据建立模型，而数字数据基本上来自简单物理学--我们几个世纪以来就知道 "简单数学适用"。但对于 ChatGPT，我们必须建立一个由人脑生成的人类语言文本模型。而对于这样的东西，我们（至少目前）还没有类似于 "简单数学 "的东西。那么，它的模型会是什么样的呢？

在谈语言之前，我们先来谈谈另一项类似人类的任务：识别图像。作为一个简单的例子，让我们来看看数字图像（没错，这是一个典型的机器学习例子）：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img34.png)

我们可以做的一件事是为每个数字获取大量样本图像：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img35.png)

那么，要想知道我们输入的图像是否对应于某个特定的数字，我们只需与现有的样本进行明确的逐像素比较即可。但作为人类，我们似乎可以做得更好--因为我们仍然可以识别数字，即使它们是手写的，而且有各种修改和变形：

![](https://content.wolfram.com/sites/43/2023/03/sw021423img36-4.png)

当我们为上面的数字数据建立模型时，我们可以利用给定的数值 $x$，针对特定的 $a$ 和 $b$ 计算出 $a + b x$。那么，如果我们把这里每个像素的灰度值看作某个变量 $x_i$，是否所有这些变量的某个函数在求值时都能告诉我们图像对应哪个数字？事实证明，构建这样一个函数是可能的。不过，它并不是特别简单，这一点也不奇怪。一个典型的例子可能涉及 50 万次数学运算。

但最终的结果是，如果我们将图像的像素值集合输入这个函数，就会得到一个数字，说明我们得到的是哪位数字的图像。稍后，我们将讨论如何构建这样一个函数，以及神经网络的概念。但现在，让我们把这个函数当作一个黑盒子，输入手写数字的图像（像素值数组），然后得到这些图像对应的数字：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img38.png)

但这究竟是怎么回事呢？假设我们逐渐模糊一个数字。有一小段时间，我们的函数仍能 "识别 "它，这里是 "2"。但很快它就 "失去了它"，开始给出 "错误 "的结果：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img39.png)

但为什么我们说这是 "错误 "的结果呢？在这种情况下，我们知道我们通过模糊 "2 "得到了所有图像。但是，如果我们的目标是建立一个人类识别图像的模型，那么真正要问的问题是，如果人类在不知道图像来源的情况下看到其中一张模糊的图像，会怎么做。

如果我们从函数中得到的结果通常与人类的说法一致，那么我们就有了一个 "好模型"。而一个非同小可的科学事实是，对于像这样的图像识别任务，我们现在基本上已经知道如何构建能做到这一点的函数。

我们能 "从数学上证明 "它们有效吗？嗯，不能。因为要做到这一点，我们必须对人类的行为有一套数学理论。以 "2 "图像为例，改变几个像素。我们可能会想，如果只有几个像素 "错位"，我们还是应该把图像看作 "2"。但这应该做到什么程度呢？这是一个人类视觉感知的问题。是的，对于蜜蜂或章鱼来说，答案无疑是不同的，而对于假想的外星人来说，答案也可能完全不同。

## Neural Nets

那么，我们用于图像识别等任务的典型模型究竟是如何工作的呢？目前最流行也是最成功的方法是使用神经网络。神经网络发明于 20 世纪 40 年代，其形式与今天的神经网络非常接近，可以看作是大脑工作方式的简单理想化。

人脑中约有 1,000 亿个神经元（神经细胞），每个神经元每秒能产生大约 1000 次电脉冲。这些神经元连接成一个复杂的网络，每个神经元都有树状分支，可以将电信号传递给成千上万个其他神经元。粗略估计，任何一个神经元在某一时刻是否会产生电脉冲，取决于它从其他神经元接收到的脉冲信号--不同的连接会产生不同的 "权重"。

当我们 "看到图像 "时，图像中的光子落到我们眼球后部的细胞（"感光器"）上，就会在神经细胞中产生电信号。这些神经细胞与其他神经细胞相连，最终这些信号会通过一连串的神经元层。正是在这个过程中，我们 "识别 "了图像，最终 "形成了 "我们 "看到了一个 2 "的想法（也许最后我们会做一些事情，比如大声说出 "2 "这个词）。

上一节中的 "黑盒 "函数就是这种神经网络的 "数学化 "版本。它恰好有 11 层（虽然只有 4 个 "核心层"）：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img40A.png)

这个神经网络并没有什么特别的 "理论来源"；它只是在 1998 年作为一项工程被构建出来，并被发现可以工作的东西。（当然，这与我们将大脑描述为生物进化过程中产生的并无太大区别）。

好吧，但这样的神经网络是如何 "识别事物 "的呢？关键在于 attractors 的概念。想象一下，我们有手写的 "1 "和 "2 "的图像：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img41.png)

我们希望所有的 1 都 "被吸引到一个地方"，而所有的 2 都 "被吸引到另一个地方"。或者换一种说法，如果一个图像 "更接近 1 "而不是 "更接近 2"，我们希望它最终出现在 "1 的位置"，反之亦然。

打个简单的比方，假设我们在平面上有一些用点表示的位置（在现实生活中，这些点可能是咖啡店的位置）。那么我们可以想象，从平面上的任何一点出发，我们总是希望到达最近的点（即我们总是去最近的咖啡店）。我们可以将平面划分为若干区域（"吸引盆地 -- attractor basins"），这些区域被理想化的 "分水岭 -- watersheds"分隔开来：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img42.png)

我们可以把这看作是在执行一种 "识别任务"，在这项任务中，我们并不是在识别给定图像 "最像 "哪位数字，而是直接查看给定点最接近哪个点。（我们在这里展示的 "Voronoi diagram "设置是在二维欧几里得空间中将点分开；数字识别任务可以被认为是在做非常类似的事情--但却是在由每幅图像中所有像素的灰度级组成的 784 维空间中）。

那么，我们该如何让神经网络 "完成识别任务 "呢？让我们来看看这个非常简单的例子：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img43.png)

我们的目标是获取与位置 {x,y} 相对应的 "输入"，然后将其 "识别 "为最接近的三个点中的任何一个。换句话说，我们希望神经网络能计算出 {x,y} 的函数，比如

![](https://content.wolfram.com/sites/43/2023/02/sw021423img44.png)

那么，我们如何利用神经网络来实现这一目标呢？归根结底，神经网络是理想化 "神经元 "的连接集合--通常分层排列--一个简单的例子就是：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img45.png)

每个 "神经元 "实际上都是用来评估一个简单的数字函数。要 "使用 "这个网络，我们只需在顶层输入数字（如坐标 x 和 y），然后让每一层的神经元 "评估它们的函数"，并将结果通过网络向前传递--最终在底层产生最终结果：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img46.png)

在传统的（受生物学启发的）设置中，每个神经元实际上都有一组来自上一层神经元的 "输入连接"，每个连接都被赋予一定的 "权重"（可以是正数或负数）。将 "前一个神经元 "的值乘以相应的权重，然后相加，再加上一个常数，最后应用一个 "阈值 -- thresholding"（或 "激活 -- activation"）函数，就能确定某个神经元的值。用数学术语来说，如果一个神经元的输入为 $x = {x1、x2 ... }$，那么我们就可以计算 $f[w . x + b]$，其中权重 $w$ 和常数 $b$ 通常是为网络中的每个神经元选择的，但函数 $f$ 通常是相同的。

计算 $w . x + b$ 只需矩阵乘法和加法。激活函数 " $f$ 引入了非线性（并最终导致了非凡的行为）。通常会使用各种激活函数，这里我们只使用 Ramp（或 ReLU）：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img48.png)

对于我们希望神经网络执行的每项任务（或者说，对于我们希望它评估的每个整体功能），我们都会有不同的权重选择。（正如我们稍后将讨论的那样，这些权重通常是通过使用机器学习的方法从我们想要的输出示例中 "训练 "神经网络来确定的）。

归根结底，每个神经网络都对应着某种整体数学函数--虽然写出来可能很乱。对于上面的例子，它应该是：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img49.png)

ChatGPT 的神经网络也只是对应于这样一个数学函数，但实际上有数十亿个项。

不过，让我们回到单个神经元上来。下面是一些例子，说明神经元在有两个输入（代表坐标 x 和 y）的情况下，通过选择不同的权重和常数（以及作为激活函数的 Ramp）可以计算的函数：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img50.png)

但从上面看，更大的网络又是怎样的呢？下面是它的计算结果：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img51.png)

虽然还不是很 "正确"，但已经接近我们上面展示的 "最近点 "函数了。

让我们看看其他神经网络的情况。在每种情况下，正如我们稍后要解释的，我们都使用机器学习来找到最佳的权重选择。然后，我们在这里展示使用这些权重的神经网络的计算结果：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img52.png)

更大的网络通常能更好地逼近我们的目标函数。在 "每个吸引子盆地 (attractor basin) 的中间"，我们通常能得到我们想要的答案。但在边界--神经网络 "很难下定决心 "的地方--情况可能会更加混乱。

在这个简单的数学式 "识别任务 "中，"正确答案 "是什么一目了然。但在识别手写数字的问题上，就不那么清楚了。如果有人把 "2 "写得像 "7 "怎么办？尽管如此，我们仍然可以问神经网络是如何区分数字的--这给出了一个提示：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img53.png)

我们能 "从数学角度 "说明网络是如何进行区分的吗？并不能。它只是 "做了神经网络所做的事"。但事实证明，通常情况下，这似乎与我们人类所做的区分相当吻合。

让我们举一个更详细的例子。假设我们有猫和狗的图像。我们有一个训练有素的神经网络来区分它们。下面是它在一些例子中的表现：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img54.png)

现在，"正确答案 "是什么就更不清楚了。一只穿着猫咪衣服的狗怎么样？等等。无论输入什么信息，神经网络都会产生一个答案，而且答案的方式与人类的方式相当一致。正如我在上文所说，这并不是我们可以 "从第一原理中推导出 "的事实。至少在某些领域，这只是经验证明的事实。但这正是神经网络有用的一个关键原因：它们以某种方式捕捉到了 "类似人类 "的做事方式。

给自己看一张猫的照片，然后问 "为什么那是一只猫？也许你会说 "嗯，我看到了它的尖耳朵等等"。但要解释你是如何认出那是一只猫并不容易。只是你的以某种方式想到了这一点。但对于大脑来说，我们没有办法（至少现在还没有办法）"进入 "它的内部，看看它是怎么想出来的。那么（人工）神经网络呢？当你展示一张猫的图片时，可以直接看到每个 "神经元 "在做什么。但即使是获得基本的可视化效果，通常也非常困难。

在我们用于上述 "最近点 "问题的最终网络中，有 17 个神经元。在识别手写数字的网络中，有 2190 个神经元。而在我们用来识别猫和狗的网络中，有 60650 个神经元。通常情况下，要将 60650 个维度的空间可视化是非常困难的。但由于这是一个为处理图像而建立的网络，它的许多神经元层都被组织成数组，就像它正在观察的像素数组一样。

如果我们以一只典型的猫为例

![](https://content.wolfram.com/sites/43/2023/02/sw021423img55.png)

那么，我们就可以用一组衍生图像来表示第一层神经元的状态--我们可以很容易地将其中许多图像解释为 "没有背景的猫 "或 "猫的轮廓"：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img56.png)

到了第 10 层，就很难解释发生了什么：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img57.png)

但一般来说，我们可以说神经网络是在 "挑选出某些特征"（也许尖耳朵就是其中之一），并利用这些特征来确定图像的内容。但是，这些特征是我们有名称的特征吗，比如 "尖耳朵"？大多不是。

我们的大脑在使用类似的功能吗？大多数情况下我们并不清楚。但值得注意的是，像我们在这里展示的这种神经网络的前几层似乎能识别出图像的某些方面（如物体的边缘），这似乎与我们所知的大脑第一层视觉处理所识别出的特征相似。

但是，假设我们想要一个神经网络的 "猫识别理论"。我们可以说"看，这个特定的网络就能做到这一点"--这立刻就能让我们感觉到这是一个 "有多难的问题"（例如，可能需要多少个神经元或多少层）。但至少到目前为止，我们还没有办法 "娓娓道来 "地描述网络在做什么。也许这是因为它在计算上确实是不可还原的，除了明确地追踪每一步之外，没有一般的方法可以找到它在做什么。或者，这只是因为我们还没有 "搞清楚这门科学"，还没有找出 "自然法则 "来让我们概括发生了什么。

当我们讨论用 ChatGPT 生成语言时，也会遇到同样的问题。同样，我们也不清楚是否有办法 "总结它在做什么"。但语言的丰富性和细节（以及我们的经验）可能会让我们比图像走得更远。

## Machine Learning, and the Training of Neural Nets

待续。

## 参考

Wolfram, S. (2023, February 14). What is ChatGPT doing ... and why does it work?. Stephen Wolfram Writings. writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work.