# What Is ChatGPT Doing … and Why Does It Work?

Stephen Wolfram, February 14, 2023

## It’s Just Adding One Word at a Time

ChatGPT 可以自动生成读起来甚至表面上像人类书写的文本，这一点非常了不起，也出乎意料。但它是如何做到的呢？它为什么能做到？我在这里的目的是粗略地介绍一下 ChatGPT 内部的情况，然后探讨它为什么能如此出色地生成我们认为有意义的文本。首先，我想说的是，我将专注于事情的全貌--虽然我会提到一些工程细节，但我不会深入探讨。（我所说内容的精髓同样适用于当前的其他 "大型语言模型"[LLMs]，也适用于 ChatGPT）。

首先要解释的是，ChatGPT 从根本上说一直在努力做的事情就是对目前所获得的文本进行 "合理的延续"，这里的 "合理 "指的是 "在看到人们在数十亿个网页上所写的内容等之后，人们可能期望某人写出的内容"。

比方说，我们有这样一段文字："The best thing about AI is its ability to"。想象一下，扫描数十亿页人类书写的文本（比如网络上和数字化书籍中的文本），然后找到这些文本的所有实例--然后再看看下一个词出现的频率是多少。ChatGPT 就能有效地做到这一点，只不过（正如我将解释的那样）它并不看文字的字面意思，而是寻找在某种意义上 "意义匹配 "的东西。但最终结果是，它会生成一个可能排在后面的词的排序列表以及 "概率"：

![Alt text](https://content.wolfram.com/sites/43/2023/02/sw021423img1.png)

最了不起的是，当 ChatGPT 做一些类似于写作文的事情时，它所做的本质上只是一遍又一遍地询问 "鉴于目前的文本，下一个词应该是什么？"--每次都添加一个词。（更准确地说，正如我将要解释的那样，它是在添加一个 "token"，这可能只是一个词的一部分，这就是为什么它有时会 "创造新词"）。

但是，好吧，在每个步骤中，它都会得到一个带概率的单词表。但它究竟应该选择哪个词添加到它正在写的文章（或其他东西）中呢？人们可能会认为应该是 "排名最高 "的词（即 "概率 "最高的词）。但就在这时，一些巫术开始悄然出现。因为出于某种原因--也许有一天我们会对这种原因有科学式的理解--如果我们总是选择排名最高的单词，我们通常会得到一篇非常 "平淡 "的作文，似乎从未 "表现出任何创造性"（甚至有时会逐字重复）。但如果有时（随意）选取排名较低的词，我们就会得到一篇 "更有趣 "的文章。

这里的随机性意味着，如果我们多次使用同一个提示，每次都可能得到不同的作文。而且，为了与巫术的理念保持一致，还有一个所谓的 "temperature" 参数，它决定了排名较低的词被使用的频率，而对于作文生成来说，0.8 的 "temperature" 似乎是最好的。（值得强调的是，这里并没有使用任何 "理论"；这只是一个在实践中行之有效的问题。举例来说，"温度 "的概念之所以存在，是因为恰好使用了统计物理学中熟悉的指数分布，但这与 "物理 "并无关联--至少就我们所知是这样）。

在我们继续之前，我应该解释一下，为了便于说明，我通常不会使用 ChatGPT 中的完整系统；相反，我通常会使用更简单的 GPT-2 系统，它有一个很好的特点，就是足够小，可以在标准的台式电脑上运行。因此，在我展示的所有内容中，我都会包含明确的 Wolfram 语言代码，您可以在自己的电脑上立即运行。(点击这里的任何图片，即可复制其背后的代码）。

例如，下面是获取上述概率表的方法。首先，我们必须检索底层的 "语言模型 "神经网络：

![Alt text](https://content.wolfram.com/sites/43/2023/02/sw021423img2.png)

稍后，我们将进入这个神经网络，了解它是如何工作的。但现在，我们只需将这个 "网络模型 "作为一个黑盒子，应用到我们目前的文本中，然后根据概率找出该模型认为应该遵循的前 5 个单词：

![Alt text](https://content.wolfram.com/sites/43/2023/02/sw021423img3.png)

这样就可以将结果转换成格式化的 "数据集"：

![Alt text](https://content.wolfram.com/sites/43/2023/02/sw021423img4.png)

下面是重复 "应用模型 "的结果--每一步都添加概率最高的单词（在此代码中指定为模型中的 "decision"）：

![Alt text](https://content.wolfram.com/sites/43/2023/02/sw021423img5.png)

如果时间再长一点会怎样？在这种（"zero temperature"）情况下，很快就会出现混乱和重复：

![Alt text](https://content.wolfram.com/sites/43/2023/02/sw021423img6.png)

但是，如果不总是选择 "顶级 "词，而是有时随机选择 "非顶级 "词（"随机性 "相当于 "temperature "0.8），又会怎样呢？同样可以建立文本：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img7.png)

而每次这样做，都会做出不同的随机选择，文本也会不同，就像这 5 个例子一样：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img8.png)

值得注意的是，即使在第一步，也有很多可能的 "下一个词 "可供选择（温度为 0.8），尽管它们的概率下降得很快（是的，对数图上的直线对应于 $n^{-1}$ 的 "幂律 "衰减，这是语言统计的一般特征）：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img10.png)

那么，如果时间更长会发生什么呢？下面是一个随机例子。这个例子比最前面那个词（zero temperature）的情况要好一些，但还是有点奇怪：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img11A.png)

这是用最简单的 GPT-2 型号（2019 年）完成的。使用更新、更大的 GPT-3 型号，效果会更好。下面是使用同样的 "提示"，但使用最大的 GPT-3 型号时产生的顶部字词（zero temperature）文本：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img12.png)

下面是一个 "温度 0.8 "的随机例子：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img13.png)

## Where Do the Probabilities Come From?

好了，ChatGPT 总是根据概率来选择下一个单词。但这些概率从何而来呢？让我们从一个更简单的问题开始。让我们考虑一次生成一个字母（而不是单词）的英文文本。我们如何计算出每个字母的概率呢？

我们可以做的最简单的事情就是抽取英文文本样本，计算不同字母在其中出现的频率。例如，计算维基百科中关于 "猫 "的文章中出现的字母：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img14-edit.png)

这对 "狗 "来说也是一样：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img15.png)

结果相似，但不尽相同（"o "无疑在 "dogs "冠词中更常见，因为毕竟它出现在 "dog "一词本身中）。尽管如此，如果我们抽取的英语文本样本足够多，我们还是可以期待最终得到至少相当一致的结果：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img16.png)

下面是我们用这些概率生成字母序列的示例：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img17.png)

我们可以通过添加空格将其分解为 "单词"，就像添加具有一定概率的字母一样：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img18.png)

我们可以通过迫使 "单词长度 "的分布与英语中的分布相一致，在制造 "单词 "方面做得更好一些：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img19.png)

我们在这里并没有得到任何 "actual words"，但结果看起来略有好转。不过，要想更进一步，我们需要做的不仅仅是随机挑选每个字母。举例来说，我们知道，如果有一个 "q"，那么下一个字母基本上就是 "u"。

下面是字母单独出现的概率图：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img20.png)

下面的图表显示了典型英语文本中成对字母（"2-grams"）的概率。可能出现的第一个字母显示在页面的横向，第二个字母显示在页面的纵向：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img21.png)

例如，我们可以看到，除了 "u "行之外，"q "列是空白的（概率为零）。好了，现在我们不再一次生成一个字母的 "单词"，而是使用这些 "2-gram "概率，一次生成两个字母的 "单词"。下面是一个结果样本--其中恰好包含了一些 "实际单词"：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img22.png)

有了足够多的英文文本，我们不仅可以对单个字母或字母对（2-grams）的概率，还可以对较长的字母组合的概率做出相当准确的估计。如果我们生成的 "随机单词 "的 n-gram 概率逐渐变长，我们就会发现它们逐渐变得 "more realistic"：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img23.png)

但是，让我们现在假设--或多或少像 ChatGPT 所做的那样--我们处理的是整个单词，而不是字母。英语中大约有 4 万个比较常用的单词。通过查看大量的英语文本语料库（比如几百万本书，共几千亿个单词），我们可以估算出每个单词的常用程度。利用这一点，我们就可以开始生成 "句子"，其中的每个单词都是独立随机抽取的，与出现在语料库中的概率相同。下面是我们得到的一个样本：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img24.png)

毫不奇怪，这是无稽之谈。那么，我们怎样才能做得更好呢？就像处理字母一样，我们不仅可以开始考虑单词的概率，还可以考虑词对或更长的 n-gram 的概率。下面是我们从 "cat"（猫）这一单词开始得到的 5 个例子：

![](https://content.wolfram.com/sites/43/2023/02/sw021423img25.png)

它看起来越来越 "合理 "了。我们可以想象，如果我们能够使用足够长的 n-gram，我们基本上就能 "得到一个 ChatGPT"--也就是说，我们会得到一个东西，它能生成具有 "正确的整体作文概率 "的作文长单词序列。但问题是：我们根本没有足够多的英语文章来推导出这些概率。

在对网络的抓取中，可能有几千亿个单词；在已经数字化的书籍中，可能又有几千亿个单词。但是，即使是 40,000 个常用词，可能出现的 2-grams 的数量也已经达到了 16 亿，而可能出现的 3-grams 的数量更是高达 60 万亿。因此，我们根本无法从现有的文本中估算出所有这些词的概率。而到了 20 个单词的 "文章片段 "时，可能性的数量已经超过了宇宙中粒子的数量，所以从某种意义上说，我们永远不可能把它们全部写下来。

那么我们能做些什么呢？最重要的想法是建立一个模型，让我们能够估算出序列出现的概率--即使我们从未在所查看的文本语料库中明确看到过这些序列。而 ChatGPT 的核心正是一个所谓的 "大型语言模型"（LLM），它的建立可以很好地估计这些概率。

## What Is a Model?

待续。

## 参考

Wolfram, S. (2023, February 14). What is ChatGPT doing ... and why does it work?. Stephen Wolfram Writings. writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work.